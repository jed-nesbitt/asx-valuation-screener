{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3f9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header found at line index: 2\n",
      "Total tickers in dataset: 1985\n",
      "Fetching P/E ratios... (this can take a while for the full dataset)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                              | 45/1985 [00:47<36:08,  1.12s/it]"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# 0. CONFIG – change these if you want\n",
    "# ================================================\n",
    "N_PER_INDUSTRY = 2      # how many cheapest companies per industry\n",
    "MAX_TICKERS = None      # set to a number (e.g. 300) to test on a subset, or None for all\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 1. Imports\n",
    "# ================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 2. Load ASX company list & fix header\n",
    "# ================================================\n",
    "csv_path = Path(\"ASXListedCompanies.csv\")\n",
    "\n",
    "# Detect header line that starts the actual table\n",
    "lines = csv_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "header_idx = None\n",
    "for i, line in enumerate(lines):\n",
    "    if line.startswith(\"Company name\"):\n",
    "        header_idx = i\n",
    "        break\n",
    "\n",
    "if header_idx is None:\n",
    "    raise ValueError(\"Could not find header line starting with 'Company name'\")\n",
    "\n",
    "print(f\"Header found at line index: {header_idx}\")\n",
    "\n",
    "# Load valid data from header onwards\n",
    "df = pd.read_csv(csv_path, skiprows=header_idx)\n",
    "\n",
    "# Optional: limit number of tickers for testing\n",
    "if MAX_TICKERS is not None:\n",
    "    df = df.head(MAX_TICKERS).copy()\n",
    "    print(f\"Using only first {len(df)} tickers for testing.\")\n",
    "else:\n",
    "    print(f\"Total tickers in dataset: {len(df)}\")\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 3. Convert ASX code -> yfinance ticker\n",
    "# ================================================\n",
    "def to_yf_ticker(asx_code: str) -> str:\n",
    "    code = str(asx_code).strip()\n",
    "    if \".\" in code:\n",
    "        return code\n",
    "    return code + \".AX\"\n",
    "\n",
    "df[\"yf_ticker\"] = df[\"ASX code\"].apply(to_yf_ticker)\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 4. Function to fetch PE ratio from yfinance\n",
    "# ================================================\n",
    "def get_pe_ratio(ticker: str):\n",
    "    try:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        pe = info.get(\"trailingPE\") or info.get(\"forwardPE\")\n",
    "        return float(pe) if pe is not None else None\n",
    "    except Exception as e:\n",
    "        # yfinance often throws 404s etc for some tickers – just log and skip\n",
    "        print(f\"Failed for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 5. Fetch P/E ratios\n",
    "# ================================================\n",
    "print(\"Fetching P/E ratios... (this can take a while for the full dataset)\")\n",
    "df[\"pe_ratio\"] = df[\"yf_ticker\"].progress_apply(get_pe_ratio)\n",
    "\n",
    "print(\"\\nSample of raw PE data:\")\n",
    "display(df.head())\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 6. Clean P/E values\n",
    "# ================================================\n",
    "df[\"pe_ratio_clean\"] = df[\"pe_ratio\"].replace([np.inf, -np.inf], np.nan)\n",
    "df.loc[df[\"pe_ratio_clean\"] <= 0, \"pe_ratio_clean\"] = np.nan\n",
    "\n",
    "filtered_df = df.dropna(subset=[\"pe_ratio_clean\"]).copy()\n",
    "\n",
    "print(f\"\\nValid P/E rows after cleaning: {len(filtered_df)}\")\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 7. Compute industry average P/E (pivot table)\n",
    "# ================================================\n",
    "industry_pe = (\n",
    "    filtered_df\n",
    "    .groupby(\"GICS industry group\")[\"pe_ratio_clean\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(\"pe_ratio_clean\")\n",
    "    .rename(columns={\"pe_ratio_clean\": \"avg_pe_ratio\"})\n",
    ")\n",
    "\n",
    "print(\"\\nIndustry average PE (pivot table):\")\n",
    "display(industry_pe)\n",
    "\n",
    "# Save pivot table\n",
    "pivot_output_path = \"industry_average_pe_full_dataset.csv\"\n",
    "industry_pe.to_csv(pivot_output_path, index=False)\n",
    "print(f\"\\nSaved pivot table to: {pivot_output_path}\")\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 8. Merge company PE with industry averages\n",
    "# ================================================\n",
    "merged = filtered_df.merge(industry_pe, on=\"GICS industry group\", how=\"left\")\n",
    "\n",
    "# Compute relative P/E (company PE / industry avg PE)\n",
    "merged[\"pe_relative\"] = merged[\"pe_ratio_clean\"] / merged[\"avg_pe_ratio\"]\n",
    "\n",
    "merged = merged.dropna(subset=[\"pe_relative\"])\n",
    "\n",
    "print(f\"\\nMerged rows with valid relative PE: {len(merged)}\")\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 9. Sort by industry + relative PE, then take N per industry\n",
    "# ================================================\n",
    "merged_sorted = merged.sort_values(\n",
    "    [\"GICS industry group\", \"pe_relative\"],\n",
    "    ascending=[True, True]\n",
    ")\n",
    "\n",
    "topN_per_industry = merged_sorted.groupby(\"GICS industry group\").head(N_PER_INDUSTRY)\n",
    "\n",
    "print(f\"\\nTop {N_PER_INDUSTRY} CHEAPEST companies per industry:\")\n",
    "display(topN_per_industry[[\n",
    "    \"GICS industry group\",\n",
    "    \"Company name\",\n",
    "    \"yf_ticker\",\n",
    "    \"pe_ratio_clean\",\n",
    "    \"avg_pe_ratio\",\n",
    "    \"pe_relative\"\n",
    "]])\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 10. Save tickers ONLY to tickers.csv\n",
    "# ================================================\n",
    "tickers_only = topN_per_industry[[\"yf_ticker\"]].rename(columns={\"yf_ticker\": \"ticker\"})\n",
    "tickers_only.to_csv(\"tickers.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved tickers.csv with the selected tickers:\")\n",
    "display(tickers_only.head())\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# DONE – only TWO CSVs are saved:\n",
    "# 1. industry_average_pe_full_dataset.csv\n",
    "# 2. tickers.csv\n",
    "# ================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58fc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
